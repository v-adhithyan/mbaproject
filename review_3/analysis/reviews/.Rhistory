reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
countWords(sentiment)
library(tidyverse)      # data manipulation & plotting
library(stringr)
library(tidytext)
data <- read.csv("reviews.csv")
reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment)
library(tidyverse)      # data manipulation & plotting
library(stringr)
library(tidytext)
library(harrypotter)    # provides the first seven novels of the Harry Potter series
data <- read.csv("reviews.csv")
reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment)
devtools::install_github("bradleyboehmke/harrypotter")
install.packages("devtools")
devtools::install_github("bradleyboehmke/harrypotter")
library(tidyverse)      # data manipulation & plotting
library(stringr)
library(tidytext)
library(harrypotter)    # provides the first seven novels of the Harry Potter series
data <- read.csv("reviews.csv")
reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment)
library(tidyverse)      # data manipulation & plotting
library(stringr)
library(tidytext)
library(harrypotter)    # provides the first seven novels of the Harry Potter series
library(dplyr)
data <- read.csv("reviews.csv")
reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>% filter(sentiment == "happy") %>%
count(sentiment)
library(tidyverse)      # data manipulation & plotting
library(stringr)
library(tidytext)
library(harrypotter)    # provides the first seven novels of the Harry Potter series
library(dplyr)
data <- read.csv("reviews.csv")
reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>% filter(sentiment == "happy")
tokens
library(tidyverse)      # data manipulation & plotting
library(stringr)
library(tidytext)
library(harrypotter)    # provides the first seven novels of the Harry Potter series
library(dplyr)
data <- read.csv("reviews.csv")
reviews <- as.vector(data['reviews'])
tokens <- data_frame(text= reviews) %>% unnest_tokens(word, text)
#tokens <- data.table::data.table(tokens)
tokens %>%
inner_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>% filter(sentiment == "happy")
tokens
require(ggplot2)
data <- read.csv("data/price.csv")
g <- ggplot(data, aes(id))
g <- g + geom_line(aes(y=sbm), color="red")
g <- g + geom_line(aes(y=sbt), color="blue")
g <- g + geom_line(aes(y=sbi), color="green")
g <- g + geom_line(aes(y=sbbj), color="magenta")
g <- g + scale_color_discrete(breaks=c("sbm", "sbt", "sbi", "sbbj"),
values=c("red", "blue", "green", "magenta"))
require(ggplot2)
data <- read.csv("price.csv")
g <- ggplot(data, aes(id))
g <- g + geom_line(aes(y=sbm), color="red")
g <- g + geom_line(aes(y=sbt), color="blue")
g <- g + geom_line(aes(y=sbi), color="green")
g <- g + geom_line(aes(y=sbbj), color="magenta")
g <- g + scale_color_discrete(breaks=c("sbm", "sbt", "sbi", "sbbj"),
values=c("red", "blue", "green", "magenta"))
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
class(data$reviews)
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
class(as.data.frame(data$reviews))
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
reviews <- as.data.frame(data$reviews)
reviews
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
result <- score.sentiment(data$reviews, pos.words, neg.words)
summary(result)
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
result <- score.sentiment(data$reviews, pos.words, neg.words)
result$score
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
result <- score.sentiment(data$reviews, pos.words = pos.words, neg.words = neg.words)
result$score
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
pos.words <- scan("pos.csv", what = 'character')
neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
result <- score.sentiment(data$reviews, pos.words = pos.words, neg.words = neg.words)
result$score
summary(result$score)
pos.words <- read.csv("pos.csv")
neg.words <- read.csv("neg.csv")
#pos.words <- scan("pos.csv", what = 'character')
#neg.words <- scan("neg.csv",what = 'character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an “l” for us
# we want a simple array (“a”) of scores back, so we use
# “l” + “a” + “ply” = “laply”:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
data <- read.csv("reviews.csv")
result <- score.sentiment(data$reviews, pos.words = pos.words, neg.words = neg.words)
result$score
library(SentimentAnalysis)
data = read.csv("reviews1.csv")
reviews <- as.vector(data['reviews'])
sentiment  <- analyzeSentiment(reviews)
#s$SentimentQDAP
convertToDirection(sentiment$SentimentQDAP)
response <- as.vector(data$response)
compareToResponse(sentiment, response)
plotSentimentResponse(sentiment$SentimentQDAP, response)
